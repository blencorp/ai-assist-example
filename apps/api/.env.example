# Backend Environment Variables
# Copy this file to .env and update with your values

# CORS origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# Environment
ENVIRONMENT=development
DEBUG=true
AI_ASSIST_API_PORT=8080

# Azure OpenAI Configuration
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_KEY=your-api-key
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o
AZURE_OPENAI_API_VERSION=2025-03-01-preview
# For production with managed identity (optional)
AZURE_CLIENT_ID=

# Vista MCP Configuration
VISTA_MCP_SERVER_URL=http://localhost:8000/mcp

# SSO Authentication Configuration
# Leave empty to disable SSO authentication
SSO_AUTH_URL=
# Example for staging: https://staff.apps-staging.example.com/sts/ssoi/v1/session/jwt
# Example for production: https://staff.apps.example.com/sts/ssoi/v1/session/jwt

SSO_AUTH_REFERRER=
# Example: https://cds.med.example.com

# SSO token cache TTL in minutes (optional, defaults to 15)
SSO_AUTH_TOKEN_TTL=15

# OpenAI Agents SDK Configuration
# NOTE: Comment out or set to 0 to enable LangSmith tracing
# OPENAI_AGENTS_DISABLE_TRACING=1

# Rate Limiting Configuration (environment-specific)
# Set delay between requests in milliseconds (0 = no delay)
# Example: 1000 = 1 second delay (for dev environments with strict limits)
RATE_LIMIT_DELAY_MS=0
# Whether to automatically retry on rate limit errors
ENABLE_RETRY_ON_RATE_LIMIT=true


# LangSmith
LANGSMITH_TRACING=true
LANGSMITH_API_KEY=
LANGSMITH_PROJECT="ai-assist-local"

# Tracing Configuration
# Set to true to include input/output data in traces (for development/debugging)
# IMPORTANT: Set to false in production when handling PHI/sensitive patient data
TRACE_INCLUDE_SENSITIVE_DATA=true
